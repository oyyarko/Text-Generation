{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_bidirectional.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HmClQYBkclop9PFdTSmXt7ddeiGvMa1r",
      "authorship_tag": "ABX9TyMGYZ+B+JQhq9Hhl4Tlzlxc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oyyarko/Text-Generation/blob/master/text_generation_bidirectional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnSnmqMfuuZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4727ca18-7bca-416e-9d72-d5d6053ccbc4"
      },
      "source": [
        "%cd /content/drive/My Drive/Deep Learning/Text Generation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Deep Learning/Text Generation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9vbZwoKwIq0",
        "colab_type": "text"
      },
      "source": [
        "# **0: Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knk0gsfiv0zC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01ea0bd3-96e8-47bf-8772-527351a924f3"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Bidirectional\n",
        "from keras.layers import LSTM, Input, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.metrics import categorical_accuracy\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "nlp.max_length = 4192709\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import codecs\n",
        "import collections\n",
        "from six.moves import cPickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPhyqj5Iw2BQ",
        "colab_type": "text"
      },
      "source": [
        "# **1:Define hyperparameters**\n",
        "\n",
        "*   Load data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqEu8wKMw0O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'text_generation_data'\n",
        "save_dir = 'save'\n",
        "file_list = [\"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"17\", \"19\", \"20\", \"21\"]\n",
        "vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
        "sequences_step = 1\n",
        "seq_length = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTLXQpdZxwty",
        "colab_type": "text"
      },
      "source": [
        "# **2:Read Data**\n",
        "\n",
        "*   spacy to tokenize\n",
        "*   convert into small letters\n",
        "*   remove single characters, numbers, whitespaces, stopwords \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcKcQEkwxu5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_wordlist(doc):\n",
        "    wl = []\n",
        "    for word in doc:\n",
        "        if word.text not in (\"\\n\", \"\\n\\n\", '\\u2009', '\\xa0'):\n",
        "            wl.append(word.text.lower())\n",
        "    return wl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsXH_IsYxikb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b724d20-3500-4c9f-816a-2ef8bf8c54a5"
      },
      "source": [
        "from tqdm import tqdm\n",
        "wordlist = []\n",
        "\n",
        "for file_name in tqdm(file_list):\n",
        "    input_file = os.path.join(data_dir, file_name + \".txt\")\n",
        "\n",
        "    with codecs.open(input_file, 'r') as f:\n",
        "        data = f.read()\n",
        "    \n",
        "    doc = nlp(data)\n",
        "    wl = create_wordlist(doc)\n",
        "    wordlist = wordlist + wl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:57<00:00, 17.76s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoIrbE9Zzbrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2dbabbd0-9a7b-4995-e5a8-1c80d58415b7"
      },
      "source": [
        "wordlist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['project',\n",
              " 'gutenberg',\n",
              " \"'s\",\n",
              " 'the',\n",
              " 'adventures',\n",
              " 'of',\n",
              " 'sherlock',\n",
              " 'holmes',\n",
              " ',',\n",
              " 'by',\n",
              " 'arthur',\n",
              " 'conan',\n",
              " 'doyle',\n",
              " 'this',\n",
              " 'ebook',\n",
              " 'is',\n",
              " 'for',\n",
              " 'the',\n",
              " 'use',\n",
              " 'of',\n",
              " 'anyone',\n",
              " 'anywhere',\n",
              " 'at',\n",
              " 'no',\n",
              " 'cost',\n",
              " 'and',\n",
              " 'with',\n",
              " 'almost',\n",
              " 'no',\n",
              " 'restrictions',\n",
              " 'whatsoever',\n",
              " '.',\n",
              " ' ',\n",
              " 'you',\n",
              " 'may',\n",
              " 'copy',\n",
              " 'it',\n",
              " ',',\n",
              " 'give',\n",
              " 'it',\n",
              " 'away',\n",
              " 'or',\n",
              " 're',\n",
              " '-',\n",
              " 'use',\n",
              " 'it',\n",
              " 'under',\n",
              " 'the',\n",
              " 'terms',\n",
              " 'of',\n",
              " 'the',\n",
              " 'project',\n",
              " 'gutenberg',\n",
              " 'license',\n",
              " 'included',\n",
              " 'with',\n",
              " 'this',\n",
              " 'ebook',\n",
              " 'or',\n",
              " 'online',\n",
              " 'at',\n",
              " 'www.gutenberg.net',\n",
              " '\\n\\n\\n',\n",
              " 'title',\n",
              " ':',\n",
              " 'the',\n",
              " 'adventures',\n",
              " 'of',\n",
              " 'sherlock',\n",
              " 'holmes',\n",
              " 'author',\n",
              " ':',\n",
              " 'arthur',\n",
              " 'conan',\n",
              " 'doyle',\n",
              " 'release',\n",
              " 'date',\n",
              " ':',\n",
              " 'november',\n",
              " '29',\n",
              " ',',\n",
              " '2002',\n",
              " '[',\n",
              " 'ebook',\n",
              " '#',\n",
              " '1661',\n",
              " ']',\n",
              " 'last',\n",
              " 'updated',\n",
              " ':',\n",
              " 'may',\n",
              " '20',\n",
              " ',',\n",
              " '2019',\n",
              " 'language',\n",
              " ':',\n",
              " 'english',\n",
              " 'character',\n",
              " 'set',\n",
              " 'encoding',\n",
              " ':',\n",
              " 'utf-8',\n",
              " '*',\n",
              " '*',\n",
              " '*',\n",
              " 'start',\n",
              " 'of',\n",
              " 'this',\n",
              " 'project',\n",
              " 'gutenberg',\n",
              " 'ebook',\n",
              " 'the',\n",
              " 'adventures',\n",
              " 'of',\n",
              " 'sherlock',\n",
              " 'holmes',\n",
              " '*',\n",
              " '*',\n",
              " '*',\n",
              " '\\n\\n\\n\\n',\n",
              " 'produced',\n",
              " 'by',\n",
              " 'an',\n",
              " 'anonymous',\n",
              " 'project',\n",
              " 'gutenberg',\n",
              " 'volunteer',\n",
              " 'and',\n",
              " 'jose',\n",
              " 'menendez',\n",
              " '\\n\\n\\n\\n',\n",
              " 'cover',\n",
              " '\\n\\n\\n\\n',\n",
              " 'the',\n",
              " 'adventures',\n",
              " 'of',\n",
              " 'sherlock',\n",
              " 'holmes',\n",
              " '\\n\\n\\n\\n',\n",
              " 'by',\n",
              " 'arthur',\n",
              " 'conan',\n",
              " 'doyle',\n",
              " '\\n\\n\\n\\n',\n",
              " 'contents',\n",
              " '\\n\\n\\n   ',\n",
              " 'i.',\n",
              " '    ',\n",
              " 'a',\n",
              " 'scandal',\n",
              " 'in',\n",
              " 'bohemia',\n",
              " '\\n   ',\n",
              " 'ii',\n",
              " '.',\n",
              " '   ',\n",
              " 'the',\n",
              " 'red',\n",
              " '-',\n",
              " 'headed',\n",
              " 'league',\n",
              " '\\n   ',\n",
              " 'iii',\n",
              " '.',\n",
              " '  ',\n",
              " 'a',\n",
              " 'case',\n",
              " 'of',\n",
              " 'identity',\n",
              " '\\n   ',\n",
              " 'iv',\n",
              " '.',\n",
              " '   ',\n",
              " 'the',\n",
              " 'boscombe',\n",
              " 'valley',\n",
              " 'mystery',\n",
              " '\\n   ',\n",
              " 'v.',\n",
              " '    ',\n",
              " 'the',\n",
              " 'five',\n",
              " 'orange',\n",
              " 'pips',\n",
              " '\\n   ',\n",
              " 'vi',\n",
              " '.',\n",
              " '   ',\n",
              " 'the',\n",
              " 'man',\n",
              " 'with',\n",
              " 'the',\n",
              " 'twisted',\n",
              " 'lip',\n",
              " '\\n   ',\n",
              " 'vii',\n",
              " '.',\n",
              " '  ',\n",
              " 'the',\n",
              " 'adventure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'blue',\n",
              " 'carbuncle',\n",
              " '\\n   ',\n",
              " 'viii',\n",
              " '.',\n",
              " ' ',\n",
              " 'the',\n",
              " 'adventure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'speckled',\n",
              " 'band',\n",
              " '\\n   ',\n",
              " 'ix',\n",
              " '.',\n",
              " '   ',\n",
              " 'the',\n",
              " 'adventure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'engineer',\n",
              " '’s',\n",
              " 'thumb',\n",
              " '\\n   ',\n",
              " 'x.',\n",
              " '    ',\n",
              " 'the',\n",
              " 'adventure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'noble',\n",
              " 'bachelor',\n",
              " '\\n   ',\n",
              " 'xi',\n",
              " '.',\n",
              " '   ',\n",
              " 'the',\n",
              " 'adventure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'beryl',\n",
              " 'coronet',\n",
              " '\\n   ',\n",
              " 'xii',\n",
              " '.',\n",
              " '  ',\n",
              " 'the',\n",
              " 'adventure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'copper',\n",
              " 'beeches',\n",
              " '\\n\\n\\n\\n',\n",
              " 'i.',\n",
              " 'a',\n",
              " 'scandal',\n",
              " 'in',\n",
              " 'bohemia',\n",
              " '\\n\\n\\n',\n",
              " 'i.',\n",
              " 'to',\n",
              " 'sherlock',\n",
              " 'holmes',\n",
              " 'she',\n",
              " 'is',\n",
              " 'always',\n",
              " '_',\n",
              " 'the',\n",
              " '_',\n",
              " 'woman',\n",
              " '.',\n",
              " 'i',\n",
              " 'have',\n",
              " 'seldom',\n",
              " 'heard',\n",
              " 'him',\n",
              " 'mention',\n",
              " 'her',\n",
              " 'under',\n",
              " 'any',\n",
              " 'other',\n",
              " 'name',\n",
              " '.',\n",
              " 'in',\n",
              " 'his',\n",
              " 'eyes',\n",
              " 'she',\n",
              " 'eclipses',\n",
              " 'and',\n",
              " 'predominates',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'of',\n",
              " 'her',\n",
              " 'sex',\n",
              " '.',\n",
              " 'it',\n",
              " 'was',\n",
              " 'not',\n",
              " 'that',\n",
              " 'he',\n",
              " 'felt',\n",
              " 'any',\n",
              " 'emotion',\n",
              " 'akin',\n",
              " 'to',\n",
              " 'love',\n",
              " 'for',\n",
              " 'irene',\n",
              " 'adler',\n",
              " '.',\n",
              " 'all',\n",
              " 'emotions',\n",
              " ',',\n",
              " 'and',\n",
              " 'that',\n",
              " 'one',\n",
              " 'particularly',\n",
              " ',',\n",
              " 'were',\n",
              " 'abhorrent',\n",
              " 'to',\n",
              " 'his',\n",
              " 'cold',\n",
              " ',',\n",
              " 'precise',\n",
              " 'but',\n",
              " 'admirably',\n",
              " 'balanced',\n",
              " 'mind',\n",
              " '.',\n",
              " 'he',\n",
              " 'was',\n",
              " ',',\n",
              " 'i',\n",
              " 'take',\n",
              " 'it',\n",
              " ',',\n",
              " 'the',\n",
              " 'most',\n",
              " 'perfect',\n",
              " 'reasoning',\n",
              " 'and',\n",
              " 'observing',\n",
              " 'machine',\n",
              " 'that',\n",
              " 'the',\n",
              " 'world',\n",
              " 'has',\n",
              " 'seen',\n",
              " ',',\n",
              " 'but',\n",
              " 'as',\n",
              " 'a',\n",
              " 'lover',\n",
              " 'he',\n",
              " 'would',\n",
              " 'have',\n",
              " 'placed',\n",
              " 'himself',\n",
              " 'in',\n",
              " 'a',\n",
              " 'false',\n",
              " 'position',\n",
              " '.',\n",
              " 'he',\n",
              " 'never',\n",
              " 'spoke',\n",
              " 'of',\n",
              " 'the',\n",
              " 'softer',\n",
              " 'passions',\n",
              " ',',\n",
              " 'save',\n",
              " 'with',\n",
              " 'a',\n",
              " 'gibe',\n",
              " 'and',\n",
              " 'a',\n",
              " 'sneer',\n",
              " '.',\n",
              " 'they',\n",
              " 'were',\n",
              " 'admirable',\n",
              " 'things',\n",
              " 'for',\n",
              " 'the',\n",
              " 'observer',\n",
              " '—',\n",
              " 'excellent',\n",
              " 'for',\n",
              " 'drawing',\n",
              " 'the',\n",
              " 'veil',\n",
              " 'from',\n",
              " 'men',\n",
              " '’s',\n",
              " 'motives',\n",
              " 'and',\n",
              " 'actions',\n",
              " '.',\n",
              " 'but',\n",
              " 'for',\n",
              " 'the',\n",
              " 'trained',\n",
              " 'reasoner',\n",
              " 'to',\n",
              " 'admit',\n",
              " 'such',\n",
              " 'intrusions',\n",
              " 'into',\n",
              " 'his',\n",
              " 'own',\n",
              " 'delicate',\n",
              " 'and',\n",
              " 'finely',\n",
              " 'adjusted',\n",
              " 'temperament',\n",
              " 'was',\n",
              " 'to',\n",
              " 'introduce',\n",
              " 'a',\n",
              " 'distracting',\n",
              " 'factor',\n",
              " 'which',\n",
              " 'might',\n",
              " 'throw',\n",
              " 'a',\n",
              " 'doubt',\n",
              " 'upon',\n",
              " 'all',\n",
              " 'his',\n",
              " 'mental',\n",
              " 'results',\n",
              " '.',\n",
              " 'grit',\n",
              " 'in',\n",
              " 'a',\n",
              " 'sensitive',\n",
              " 'instrument',\n",
              " ',',\n",
              " 'or',\n",
              " 'a',\n",
              " 'crack',\n",
              " 'in',\n",
              " 'one',\n",
              " 'of',\n",
              " 'his',\n",
              " 'own',\n",
              " 'high',\n",
              " '-',\n",
              " 'power',\n",
              " 'lenses',\n",
              " ',',\n",
              " 'would',\n",
              " 'not',\n",
              " 'be',\n",
              " 'more',\n",
              " 'disturbing',\n",
              " 'than',\n",
              " 'a',\n",
              " 'strong',\n",
              " 'emotion',\n",
              " 'in',\n",
              " 'a',\n",
              " 'nature',\n",
              " 'such',\n",
              " 'as',\n",
              " 'his',\n",
              " '.',\n",
              " 'and',\n",
              " 'yet',\n",
              " 'there',\n",
              " 'was',\n",
              " 'but',\n",
              " 'one',\n",
              " 'woman',\n",
              " 'to',\n",
              " 'him',\n",
              " ',',\n",
              " 'and',\n",
              " 'that',\n",
              " 'woman',\n",
              " 'was',\n",
              " 'the',\n",
              " 'late',\n",
              " 'irene',\n",
              " 'adler',\n",
              " ',',\n",
              " 'of',\n",
              " 'dubious',\n",
              " 'and',\n",
              " 'questionable',\n",
              " 'memory',\n",
              " '.',\n",
              " 'i',\n",
              " 'had',\n",
              " 'seen',\n",
              " 'little',\n",
              " 'of',\n",
              " 'holmes',\n",
              " 'lately',\n",
              " '.',\n",
              " 'my',\n",
              " 'marriage',\n",
              " 'had',\n",
              " 'drifted',\n",
              " 'us',\n",
              " 'away',\n",
              " 'from',\n",
              " 'each',\n",
              " 'other',\n",
              " '.',\n",
              " 'my',\n",
              " 'own',\n",
              " 'complete',\n",
              " 'happiness',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'home',\n",
              " '-',\n",
              " 'centred',\n",
              " 'interests',\n",
              " 'which',\n",
              " 'rise',\n",
              " 'up',\n",
              " 'around',\n",
              " 'the',\n",
              " 'man',\n",
              " 'who',\n",
              " 'first',\n",
              " 'finds',\n",
              " 'himself',\n",
              " 'master',\n",
              " 'of',\n",
              " 'his',\n",
              " 'own',\n",
              " 'establishment',\n",
              " ',',\n",
              " 'were',\n",
              " 'sufficient',\n",
              " 'to',\n",
              " 'absorb',\n",
              " 'all',\n",
              " 'my',\n",
              " 'attention',\n",
              " ',',\n",
              " 'while',\n",
              " 'holmes',\n",
              " ',',\n",
              " 'who',\n",
              " 'loathed',\n",
              " 'every',\n",
              " 'form',\n",
              " 'of',\n",
              " 'society',\n",
              " 'with',\n",
              " 'his',\n",
              " 'whole',\n",
              " 'bohemian',\n",
              " 'soul',\n",
              " ',',\n",
              " 'remained',\n",
              " 'in',\n",
              " 'our',\n",
              " 'lodgings',\n",
              " 'in',\n",
              " 'baker',\n",
              " 'street',\n",
              " ',',\n",
              " 'buried',\n",
              " 'among',\n",
              " 'his',\n",
              " 'old',\n",
              " 'books',\n",
              " ',',\n",
              " 'and',\n",
              " 'alternating',\n",
              " 'from',\n",
              " 'week',\n",
              " 'to',\n",
              " 'week',\n",
              " 'between',\n",
              " 'cocaine',\n",
              " 'and',\n",
              " 'ambition',\n",
              " ',',\n",
              " 'the',\n",
              " 'drowsiness',\n",
              " 'of',\n",
              " 'the',\n",
              " 'drug',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'fierce',\n",
              " 'energy',\n",
              " 'of',\n",
              " 'his',\n",
              " 'own',\n",
              " 'keen',\n",
              " 'nature',\n",
              " '.',\n",
              " 'he',\n",
              " 'was',\n",
              " 'still',\n",
              " ',',\n",
              " 'as',\n",
              " 'ever',\n",
              " ',',\n",
              " 'deeply',\n",
              " 'attracted',\n",
              " 'by',\n",
              " 'the',\n",
              " 'study',\n",
              " 'of',\n",
              " 'crime',\n",
              " ',',\n",
              " 'and',\n",
              " 'occupied',\n",
              " 'his',\n",
              " 'immense',\n",
              " 'faculties',\n",
              " 'and',\n",
              " 'extraordinary',\n",
              " 'powers',\n",
              " 'of',\n",
              " 'observation',\n",
              " 'in',\n",
              " 'following',\n",
              " 'out',\n",
              " 'those',\n",
              " 'clues',\n",
              " ',',\n",
              " 'and',\n",
              " 'clearing',\n",
              " 'up',\n",
              " 'those',\n",
              " 'mysteries',\n",
              " 'which',\n",
              " 'had',\n",
              " 'been',\n",
              " 'abandoned',\n",
              " 'as',\n",
              " 'hopeless',\n",
              " 'by',\n",
              " 'the',\n",
              " 'official',\n",
              " 'police',\n",
              " '.',\n",
              " 'from',\n",
              " 'time',\n",
              " 'to',\n",
              " 'time',\n",
              " 'i',\n",
              " 'heard',\n",
              " 'some',\n",
              " 'vague',\n",
              " 'account',\n",
              " 'of',\n",
              " 'his',\n",
              " 'doings',\n",
              " ':',\n",
              " 'of',\n",
              " 'his',\n",
              " 'summons',\n",
              " 'to',\n",
              " 'odessa',\n",
              " 'in',\n",
              " 'the',\n",
              " 'case',\n",
              " 'of',\n",
              " 'the',\n",
              " 'trepoff',\n",
              " 'murder',\n",
              " ',',\n",
              " 'of',\n",
              " 'his',\n",
              " 'clearing',\n",
              " 'up',\n",
              " 'of',\n",
              " 'the',\n",
              " 'singular',\n",
              " 'tragedy',\n",
              " 'of',\n",
              " 'the',\n",
              " 'atkinson',\n",
              " 'brothers',\n",
              " 'at',\n",
              " 'trincomalee',\n",
              " ',',\n",
              " 'and',\n",
              " 'finally',\n",
              " 'of',\n",
              " 'the',\n",
              " 'mission',\n",
              " 'which',\n",
              " 'he',\n",
              " 'had',\n",
              " 'accomplished',\n",
              " 'so',\n",
              " 'delicately',\n",
              " 'and',\n",
              " 'successfully',\n",
              " 'for',\n",
              " 'the',\n",
              " 'reigning',\n",
              " 'family',\n",
              " 'of',\n",
              " 'holland',\n",
              " '.',\n",
              " 'beyond',\n",
              " 'these',\n",
              " 'signs',\n",
              " 'of',\n",
              " 'his',\n",
              " 'activity',\n",
              " ',',\n",
              " 'however',\n",
              " ',',\n",
              " 'which',\n",
              " 'i',\n",
              " 'merely',\n",
              " 'shared',\n",
              " 'with',\n",
              " 'all',\n",
              " 'the',\n",
              " 'readers',\n",
              " 'of',\n",
              " 'the',\n",
              " 'daily',\n",
              " 'press',\n",
              " ',',\n",
              " 'i',\n",
              " 'knew',\n",
              " 'little',\n",
              " 'of',\n",
              " 'my',\n",
              " 'former',\n",
              " 'friend',\n",
              " 'and',\n",
              " 'companion',\n",
              " '.',\n",
              " 'one',\n",
              " 'night',\n",
              " '—',\n",
              " 'it',\n",
              " 'was',\n",
              " 'on',\n",
              " 'the',\n",
              " 'twentieth',\n",
              " 'of',\n",
              " 'march',\n",
              " ',',\n",
              " '1888—i',\n",
              " 'was',\n",
              " 'returning',\n",
              " 'from',\n",
              " 'a',\n",
              " 'journey',\n",
              " 'to',\n",
              " 'a',\n",
              " 'patient',\n",
              " '(',\n",
              " 'for',\n",
              " 'i',\n",
              " 'had',\n",
              " 'now',\n",
              " 'returned',\n",
              " 'to',\n",
              " 'civil',\n",
              " 'practice',\n",
              " ')',\n",
              " ',',\n",
              " 'when',\n",
              " 'my',\n",
              " 'way',\n",
              " 'led',\n",
              " 'me',\n",
              " 'through',\n",
              " 'baker',\n",
              " 'street',\n",
              " '.',\n",
              " 'as',\n",
              " 'i',\n",
              " 'passed',\n",
              " 'the',\n",
              " 'well',\n",
              " '-',\n",
              " 'remembered',\n",
              " 'door',\n",
              " ',',\n",
              " 'which',\n",
              " 'must',\n",
              " 'always',\n",
              " 'be',\n",
              " 'associated',\n",
              " 'in',\n",
              " 'my',\n",
              " 'mind',\n",
              " 'with',\n",
              " 'my',\n",
              " 'wooing',\n",
              " ',',\n",
              " 'and',\n",
              " 'with',\n",
              " 'the',\n",
              " 'dark',\n",
              " 'incidents',\n",
              " 'of',\n",
              " 'the',\n",
              " 'study',\n",
              " 'in',\n",
              " 'scarlet',\n",
              " ',',\n",
              " 'i',\n",
              " 'was',\n",
              " 'seized',\n",
              " 'with',\n",
              " 'a',\n",
              " 'keen',\n",
              " 'desire',\n",
              " 'to',\n",
              " 'see',\n",
              " 'holmes',\n",
              " 'again',\n",
              " ',',\n",
              " 'and',\n",
              " 'to',\n",
              " 'know',\n",
              " 'how',\n",
              " 'he',\n",
              " 'was',\n",
              " 'employing',\n",
              " 'his',\n",
              " 'extraordinary',\n",
              " 'powers',\n",
              " '.',\n",
              " 'his',\n",
              " 'rooms',\n",
              " 'were',\n",
              " 'brilliantly',\n",
              " 'lit',\n",
              " ',',\n",
              " 'and',\n",
              " ',',\n",
              " 'even',\n",
              " 'as',\n",
              " 'i',\n",
              " 'looked',\n",
              " 'up',\n",
              " ',',\n",
              " 'i',\n",
              " 'saw',\n",
              " 'his',\n",
              " 'tall',\n",
              " ',',\n",
              " 'spare',\n",
              " 'figure',\n",
              " 'pass',\n",
              " 'twice',\n",
              " 'in',\n",
              " 'a',\n",
              " 'dark',\n",
              " 'silhouette',\n",
              " 'against',\n",
              " 'the',\n",
              " 'blind',\n",
              " '.',\n",
              " 'he',\n",
              " 'was',\n",
              " 'pacing',\n",
              " 'the',\n",
              " 'room',\n",
              " 'swiftly',\n",
              " ',',\n",
              " 'eagerly',\n",
              " ',',\n",
              " 'with',\n",
              " 'his',\n",
              " 'head',\n",
              " 'sunk',\n",
              " 'upon',\n",
              " 'his',\n",
              " 'chest',\n",
              " 'and',\n",
              " 'his',\n",
              " 'hands',\n",
              " 'clasped',\n",
              " 'behind',\n",
              " 'him',\n",
              " '.',\n",
              " 'to',\n",
              " 'me',\n",
              " ',',\n",
              " 'who',\n",
              " 'knew',\n",
              " 'his',\n",
              " 'every',\n",
              " 'mood',\n",
              " 'and',\n",
              " 'habit',\n",
              " ',',\n",
              " 'his',\n",
              " 'attitude',\n",
              " 'and',\n",
              " 'manner',\n",
              " 'told',\n",
              " 'their',\n",
              " 'own',\n",
              " 'story',\n",
              " '.',\n",
              " 'he',\n",
              " 'was',\n",
              " 'at',\n",
              " 'work',\n",
              " 'again',\n",
              " '.',\n",
              " 'he',\n",
              " 'had',\n",
              " 'risen',\n",
              " 'out',\n",
              " 'of',\n",
              " 'his',\n",
              " 'drug',\n",
              " '-',\n",
              " 'created',\n",
              " 'dreams',\n",
              " 'and',\n",
              " 'was',\n",
              " 'hot',\n",
              " 'upon',\n",
              " 'the',\n",
              " 'scent',\n",
              " 'of',\n",
              " 'some',\n",
              " 'new',\n",
              " 'problem',\n",
              " '.',\n",
              " 'i',\n",
              " 'rang',\n",
              " 'the',\n",
              " 'bell',\n",
              " 'and',\n",
              " 'was',\n",
              " 'shown',\n",
              " 'up',\n",
              " 'to',\n",
              " 'the',\n",
              " 'chamber',\n",
              " 'which',\n",
              " 'had',\n",
              " 'formerly',\n",
              " 'been',\n",
              " 'in',\n",
              " 'part',\n",
              " 'my',\n",
              " 'own',\n",
              " '.',\n",
              " 'his',\n",
              " 'manner',\n",
              " 'was',\n",
              " 'not',\n",
              " 'effusive',\n",
              " '.',\n",
              " 'it',\n",
              " 'seldom',\n",
              " 'was',\n",
              " ';',\n",
              " 'but',\n",
              " 'he',\n",
              " 'was',\n",
              " 'glad',\n",
              " ',',\n",
              " 'i',\n",
              " 'think',\n",
              " ',',\n",
              " 'to',\n",
              " 'see',\n",
              " 'me',\n",
              " '.',\n",
              " 'with',\n",
              " 'hardly',\n",
              " 'a',\n",
              " 'word',\n",
              " 'spoken',\n",
              " ',',\n",
              " 'but',\n",
              " 'with',\n",
              " 'a',\n",
              " 'kindly',\n",
              " 'eye',\n",
              " ',',\n",
              " 'he',\n",
              " 'waved',\n",
              " 'me',\n",
              " 'to',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Zfo_Rx4Yc3",
        "colab_type": "text"
      },
      "source": [
        "# **Create Dictionary**\n",
        "*   For each word with it's index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaQmV1hn4Ds4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf96b457-0d7a-482f-cba2-cf1affc435c9"
      },
      "source": [
        "#count the number of words\n",
        "word_counts = collections.Counter(wordlist)\n",
        "\n",
        "#mapping index to words\n",
        "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
        "vocabulary_inv = list(sorted(vocabulary_inv))\n",
        "\n",
        "#mapping words to index into dict\n",
        "vocab = {x: i for i,x in enumerate(vocabulary_inv)}\n",
        "words = [x[0] for x in word_counts.most_common()]\n",
        "\n",
        "#size of the vocabulary\n",
        "vocab_size = len(words)\n",
        "print(\"vocab size: \", vocab_size)\n",
        "\n",
        "#save words into pickle file\n",
        "\n",
        "with open(os.path.join(vocab_file), \"wb\") as f:\n",
        "    cPickle.dump((words, vocab, vocabulary_inv), f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size:  40823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKiwWGZ86zQX",
        "colab_type": "text"
      },
      "source": [
        "# **Create Sequences**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SarhY0R570t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "925027a9-28bc-4711-f2dc-f1b06f81b866"
      },
      "source": [
        "#create sequences\n",
        "sequences = []\n",
        "next_words = []\n",
        "\n",
        "for i in range(0, len(wordlist)-seq_length, sequences_step):\n",
        "    sequences.append(wordlist[i: i+seq_length])\n",
        "    next_words.append(wordlist[i+seq_length])\n",
        "\n",
        "print(\"nb sequences: \", len(sequences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences:  1294250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2GMARjU79hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), vocab_size), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(sequences):\n",
        "    for t, word in enumerate(sentence):\n",
        "        X[i, t, vocab[word]] = 1\n",
        "    y[i, vocab[next_words[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvO3Vsi69dp6",
        "colab_type": "text"
      },
      "source": [
        "# **Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuJtyrRC_cq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bidirectional_lstm_model(seq_length, vocab_size):\n",
        "    print('Build LSTM model.')\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(rnn_size, activation=\"relu\"),input_shape=(seq_length, vocab_size)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    optimizer = Adam(lr=learning_rate)\n",
        "    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5LYvlCGKeF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_size = 256\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeul7f_DKvE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = bidirectional_lstm_model(seq_length, vocab_size)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1wqyFz7LtTa",
        "colab_type": "text"
      },
      "source": [
        "# **Train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "metqZGMUL5xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPQ0_-XXLlEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks=[EarlyStopping(patience=4, monitor='val_loss'),\n",
        "           ModelCheckpoint(filepath=save_dir + \"/\" + 'my_model_gen_sentences_lstm.{epoch:02d}-{val_loss:.2f}.hdf5',\\\n",
        "                           monitor='val_loss', verbose=0, mode='auto', period=2)]\n",
        "history = model.fit(X, y,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=True,\n",
        "                 epochs=num_epochs,\n",
        "                 callbacks=callbacks,\n",
        "                 validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMUGliQDMoCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}